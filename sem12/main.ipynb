{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Композиции классификаторов (градиентный бустинг)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3qWY0M5LA6r",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from mpl_toolkits import mplot3d\n",
    "from copy import deepcopy\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "from sklearn import tree, base\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, BaggingClassifier)\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.datasets import make_classification, make_regression, load_wine, load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision import datasets, transforms\n",
    "import pyfpgrowth\n",
    "import torch\n",
    "from mixturelib.mixture import MixtureEM\n",
    "from mixturelib.local_models import EachModelLinear\n",
    "from mixturelib.hyper_models import HyperExpertNN, HyperModelDirichlet\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ComBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComBoost(object):\n",
    "    def __init__(self, base_estimator=None, n_estimators=10):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "        if base_estimator:\n",
    "            self.base_estimator = base_estimator\n",
    "            \n",
    "        self.b = [base.clone(self.base_estimator) for _ in range(self.n_estimators)]\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return {'n_estimators': self.n_estimators, \n",
    "                'base_estimator': self.base_estimator}\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_predict_proba(pred, b, b0):\n",
    "        new_pred = np.zeros((len(pred), len(b0.classes_)))\n",
    "\n",
    "        for i, cl in enumerate(b.classes_):\n",
    "            new_pred[:, cl] = pred[:, i]\n",
    "\n",
    "        return new_pred\n",
    "        \n",
    "    def fit(self, X, Y, l0=0, l1=100, l2=None, dl=100):\n",
    "        def margin(pr, y):\n",
    "            cop = pr.copy()\n",
    "            cop[y] = -1\n",
    "            return pr[y] - cop.max()\n",
    "        \n",
    "        if l2 is None:\n",
    "            l2 = len(X)\n",
    "        \n",
    "        for t, b in enumerate(self.b):\n",
    "            if t == 0:\n",
    "                b.fit(X, Y)\n",
    "                pred = b.predict_proba(X)\n",
    "                M = np.array([margin(pred[i], Y[i]) for i in range(len(Y))])\n",
    "            else:\n",
    "                indexes = sorted(np.arange(0, len(X)), key = lambda i: M[i])\n",
    "                X_new = X[indexes]\n",
    "                Y_new = Y[indexes]\n",
    "                dict_of_param = []\n",
    "                for k in range(l1, l2, dl):\n",
    "                    new_item = {'l0': l0, \n",
    "                                'k': k}\n",
    "                    \n",
    "                    local_b = base.clone(self.base_estimator)\n",
    "                    local_b.fit(X_new[l0:k], Y_new[l0:k])\n",
    "                    \n",
    "                    pred = self.fix_predict_proba(local_b.predict_proba(X), local_b, self.b[0])\n",
    "                    M_new = np.array([margin(pred[i], Y[i]) for i in range(len(Y))])\n",
    "                    \n",
    "                    new_item['Q'] = (M+M_new < 0).sum()\n",
    "                    dict_of_param.append(new_item)\n",
    "                    \n",
    "                element = sorted(dict_of_param, key=lambda x: x['Q'])[0]\n",
    "                b.fit(X_new[element['l0']:element['k']], \n",
    "                      Y_new[element['l0']:element['k']])\n",
    "                \n",
    "                pred = self.fix_predict_proba(b.predict_proba(X), local_b, self.b[0])\n",
    "                M = M + np.array([margin(pred[i], Y[i]) for i in range(len(Y))])\n",
    "                \n",
    "                    \n",
    "    def predict(self, X):\n",
    "        probas = self.predict_proba(X)\n",
    "        return np.argmax(probas, axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.mean([self.fix_predict_proba(elem.predict_proba(X), elem, self.b[0]) for elem in self.b], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.801 (0.038)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "model = ComBoost(DecisionTreeClassifier(max_depth=2))\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.950 (0.019)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "model = ComBoost(SVC(probability=True))\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.798 (0.034)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "model = ComBoost(LogisticRegression())\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostingRegression(object):\n",
    "    def __init__(self, base_estimator=None, n_estimators=10):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.base_estimator = DecisionTreeRegressor(max_depth=1)\n",
    "        if base_estimator:\n",
    "            self.base_estimator = base_estimator\n",
    "            \n",
    "        self.b = [base.clone(self.base_estimator) for _ in range(self.n_estimators)]\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return {'n_estimators': self.n_estimators, \n",
    "                'base_estimator': self.base_estimator}\n",
    "        \n",
    "    def score(self, X, Y):\n",
    "        return ((self.predict(X) - Y)**2).mean()\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        residual = Y.copy()\n",
    "        for t, b in enumerate(self.b):\n",
    "            b.fit(X, residual)\n",
    "            residual -= b.predict(X)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return np.sum([elem.predict(X) for elem in self.b], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 5392.988 (837.368)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=20, random_state=6)\n",
    "model = GradientBoostingRegression(DecisionTreeRegressor(max_depth=2))\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1)\n",
    "print('SCORE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 5340.377 (1169.583)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=20, random_state=6)\n",
    "model = GradientBoostingRegression(SVR())\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1)\n",
    "print('SCORE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.002 (0.000)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=20, random_state=6)\n",
    "model = GradientBoostingRegression(SVR(kernel='linear'))\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1)\n",
    "print('SCORE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.000 (0.000)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=20, random_state=6)\n",
    "model = GradientBoostingRegression(LinearRegression())\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1)\n",
    "print('SCORE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.909 (0.034)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "model = xgb.XGBClassifier(objective='binary:logistic', random_state=6)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1)\n",
    "print('SCORE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.883 (0.018)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=20, random_state=6)\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', random_state=6)\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1)\n",
    "print('SCORE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.749 (0.034)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "\n",
    "model = CatBoostClassifier(iterations=2,\n",
    "                           depth=2,\n",
    "                           learning_rate=1,\n",
    "                           loss_function='Logloss',\n",
    "                           verbose=True, task_type='CPU')\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1)\n",
    "print('SCORE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
